{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c91bdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octoopt/workspace/projects/learn-from-basics/nlp-vietnamese-phd/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")\n",
    "model_name = \"NlpHUST/ner-vietnamese-electra-base\"\n",
    "query = \"Mục lục NỘI THIÊN NỘI THIÊN 2 NỘI THIÊN 3 Các sách chú giải Trang Tử HỌC THUYẾT CỦA TRANG TỬ HỌC THUYẾT CỦA TRANG TỬ 2 TIÊU- DIÊU- DU TỔNG BÌNH TỀ- VẬT- LUẬN Phải Quấy và Xấu Tốt ĐỨC SUNG PHÙ\"\n",
    "\n",
    "\n",
    "result = client.token_classification(\n",
    "    query,\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ffbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(query)\n",
    "print(tokens)\n",
    "\n",
    "for token in tokens:\n",
    "    print(token)\n",
    "    result = client.token_classification(model=model_name, text=token)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291518f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "# from transformers import pipeline\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"NlpHUST/ner-vietnamese-electra-base\")\n",
    "# model = AutoModelForTokenClassification.from_pretrained(\"NlpHUST/ner-vietnamese-electra-base\")\n",
    "\n",
    "# nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "# example = \"Liên quan vụ việc CSGT bị tố đánh dân, trúng một cháu nhỏ đang ngủ, đang lan truyền trên mạng xã hội, Đại tá Nguyễn Văn Tảo, Phó Giám đốc Công an tỉnh Tiền Giang vừa có cuộc họp cùng Chỉ huy Công an huyện Châu Thành và một số đơn vị nghiệp vụ cấp tỉnh để chỉ đạo làm rõ thông tin.\"\n",
    "\n",
    "# ner_results = nlp(example)\n",
    "# print(ner_results)\n",
    "# model_name = \"undertheseanlp/vietnamese-ner-v1.4.0a2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872319ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"start\": 1,\n",
      "    \"end\": 5,\n",
      "    \"word\": \"TRANG\",\n",
      "    \"entity_group\": \"PER\"\n",
      "  },\n",
      "  {\n",
      "    \"start\": 20,\n",
      "    \"end\": 37,\n",
      "    \"word\": \"TIÊU-DIÊU-DU TỔNG BÌNH\",\n",
      "    \"entity_group\": \"TITLE\"\n",
      "  },\n",
      "  {\n",
      "    \"start\": 41,\n",
      "    \"end\": 50,\n",
      "    \"word\": \"TỀ-VẬT-LUẬN\",\n",
      "    \"entity_group\": \"TITLE\"\n",
      "  }\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class NERResponse(BaseModel):\n",
    "    end: int\n",
    "    score: float\n",
    "    start: int\n",
    "    word: str\n",
    "    entity: str\n",
    "    entity_group: str\n",
    "\n",
    "\n",
    "NER_PROMPT = \"\"\"\n",
    "Nhiệm vụ: Nhận diện thực thể có tên (NER) trong văn bản tiếng Việt.\n",
    "\n",
    "Bạn là mô hình NER. Hãy trích xuất các thực thể trong văn bản và phân loại chúng vào một trong các nhóm sau:\n",
    "- PER: Tên người\n",
    "- LOC: Địa danh\n",
    "- ORG: Tổ chức\n",
    "- TME: Thời gian\n",
    "- TITLE: Tựa đề\n",
    "- NUM: Số\n",
    "\n",
    "Trả về kết quả dưới dạng danh sách JSON. Mỗi thực thể gồm các trường:\n",
    "- start: vị trí bắt đầu (ký tự)\n",
    "- end: vị trí kết thúc (ký tự)\n",
    "- word: văn bản của thực thể\n",
    "- entity_group: loại thực thể\n",
    "\n",
    "Chỉ trả về JSON. Nếu không có thực thể, trả về `[]`.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "    # base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "    base_url=\"https://api.groq.com/openai/v1/\",\n",
    ")\n",
    "\n",
    "query = \"Mục lục NỘI THIÊN NỘI THIÊN 2 NỘI THIÊN 3 Các sách chú giải Trang Tử HỌC THUYẾT CỦA TRANG TỬ HỌC THUYẾT CỦA TRANG TỬ 2 TIÊU- DIÊU- DU TỔNG BÌNH TỀ- VẬT- LUẬN Phải Quấy và Xấu Tốt ĐỨC SUNG PHÙ\"\n",
    "\n",
    "completion = await client.chat.completions.create(\n",
    "    model=\"gemma2-9b-it\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": NER_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ],\n",
    "    # response_format=NERResponse,\n",
    ")\n",
    "\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b074a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed JSON:\n",
      "{'start': 2, 'end': 5, 'word': 'TRANG', 'entity_group': 'PER', 'score': 0.99}\n",
      "{'start': 8, 'end': 13, 'word': 'TÙY', 'entity_group': 'PER', 'score': 0.99}\n",
      "{'start': 29, 'end': 38, 'word': 'TRANG TỬ', 'entity_group': 'PER', 'score': 0.99}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Your string with markdown code blocks\n",
    "markdown_string = completion.choices[0].message.content\n",
    "\n",
    "# Remove markdown code block markers\n",
    "json_string = re.sub(r\"^```json\\n|\\n```$\", \"\", markdown_string.strip())\n",
    "\n",
    "# Parse the JSON\n",
    "try:\n",
    "    entities = json.loads(json_string)\n",
    "    print(\"Successfully parsed JSON:\")\n",
    "    for entity in entities:\n",
    "        # print(f\"Entity: {entity['word']} (Type: {entity['entity_group']})\")\n",
    "        print(entity)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error parsing JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab6aac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/llama-4-maverick-17b-128e-instruct\n",
      "meta-llama/llama-guard-4-12b\n",
      "deepseek-r1-distill-llama-70b\n",
      "llama-3.1-8b-instant\n",
      "compound-beta\n",
      "playai-tts\n",
      "compound-beta-mini\n",
      "llama3-70b-8192\n",
      "qwen/qwen3-32b\n",
      "whisper-large-v3\n",
      "llama3-8b-8192\n",
      "meta-llama/llama-4-scout-17b-16e-instruct\n",
      "distil-whisper-large-v3-en\n",
      "qwen-qwq-32b\n",
      "gemma2-9b-it\n",
      "allam-2-7b\n",
      "whisper-large-v3-turbo\n",
      "mistral-saba-24b\n",
      "meta-llama/llama-prompt-guard-2-22m\n",
      "playai-tts-arabic\n",
      "llama-3.3-70b-versatile\n",
      "meta-llama/llama-prompt-guard-2-86m\n"
     ]
    }
   ],
   "source": [
    "models = await client.models.list()\n",
    "for model in models.data:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19e0773a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': np.float32(0.9695143),\n",
       "  'index': 10,\n",
       "  'word': 'Nghệ',\n",
       "  'start': 29,\n",
       "  'end': 33},\n",
       " {'entity': 'B-PER',\n",
       "  'score': np.float32(0.998722),\n",
       "  'index': 12,\n",
       "  'word': 'Văn',\n",
       "  'start': 35,\n",
       "  'end': 38},\n",
       " {'entity': 'B-PER',\n",
       "  'score': np.float32(0.9946812),\n",
       "  'index': 14,\n",
       "  'word': 'Chí',\n",
       "  'start': 40,\n",
       "  'end': 43}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from underthesea import ner\n",
    "\n",
    "query = \"Sách Trang tử, theo Hán- thư Nghệ- Văn- Chí, thì có đến năm mươi hai(52) thiên. Nay chỉ thấy còn có ba mươi ba (33) thiên.\"\n",
    "\n",
    "result = ner(query, deep=True)\n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75433194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'B-PER', 'score': np.float32(0.99410796), 'index': 4, 'word': 'NỘI', 'start': 8, 'end': 11}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.9984523), 'index': 7, 'word': 'THIÊN', 'start': 12, 'end': 17}\n",
      "{'entity': 'B-PER', 'score': np.float32(0.62662), 'index': 11, 'word': 'NỘI', 'start': 18, 'end': 21}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.9986203), 'index': 14, 'word': 'THIÊNỘI', 'start': 22, 'end': 33}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.9710959), 'index': 22, 'word': 'THIÊNỌC', 'start': 34, 'end': 72}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.71561724), 'index': 36, 'word': 'THUY', 'start': 73, 'end': 77}\n",
      "{'entity': 'B-PER', 'score': np.float32(0.99817026), 'index': 45, 'word': 'TRANG', 'start': 84, 'end': 89}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.9992786), 'index': 48, 'word': 'TỬỌ', 'start': 90, 'end': 95}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.58109605), 'index': 53, 'word': 'THUY', 'start': 97, 'end': 101}\n",
      "{'entity': 'B-PER', 'score': np.float32(0.99750465), 'index': 62, 'word': 'TRANG', 'start': 108, 'end': 113}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.9992543), 'index': 65, 'word': 'TỬ', 'start': 114, 'end': 116}\n",
      "{'entity': 'B-PER', 'score': np.float32(0.7456495), 'index': 68, 'word': 'TIÊU', 'start': 119, 'end': 123}\n",
      "{'entity': 'B-PER', 'score': np.float32(0.8863496), 'index': 73, 'word': 'DIÊU', 'start': 125, 'end': 129}\n",
      "{'entity': 'B-PER', 'score': np.float32(0.9997142), 'index': 77, 'word': 'DU', 'start': 131, 'end': 133}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.9982774), 'index': 79, 'word': 'TỔNG', 'start': 134, 'end': 138}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.97955817), 'index': 82, 'word': 'BÌNH', 'start': 139, 'end': 143}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.9869686), 'index': 85, 'word': 'TỀ', 'start': 144, 'end': 146}\n",
      "{'entity': 'B-PER', 'score': np.float32(0.85740644), 'index': 88, 'word': 'VẬT', 'start': 148, 'end': 151}\n",
      "{'entity': 'B-PER', 'score': np.float32(0.9995963), 'index': 92, 'word': 'LUẬN', 'start': 153, 'end': 157}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.82874006), 'index': 96, 'word': 'Phảiấy', 'start': 158, 'end': 167}\n",
      "{'entity': 'B-PER', 'score': np.float32(0.91174746), 'index': 101, 'word': 'Xấu', 'start': 171, 'end': 174}\n",
      "{'entity': 'I-ORG', 'score': np.float32(0.87361157), 'index': 103, 'word': 'Tốt', 'start': 175, 'end': 178}\n",
      "{'entity': 'B-PER', 'score': np.float32(0.98563725), 'index': 105, 'word': 'ĐỨC', 'start': 179, 'end': 182}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.9946404), 'index': 108, 'word': 'SUNG', 'start': 183, 'end': 187}\n",
      "{'entity': 'I-PER', 'score': np.float32(0.9979504), 'index': 110, 'word': 'PHÙ', 'start': 188, 'end': 191}\n"
     ]
    }
   ],
   "source": [
    "base_entities = [\n",
    "    \"PER\",\n",
    "    \"ORG\",\n",
    "    \"LOC\",\n",
    "    \"ORG\",\n",
    "    \"TME\",\n",
    "    \"TITLE\",\n",
    "    \"NUM\",\n",
    "]\n",
    "\n",
    "for r in result: \n",
    "    base_entity = r.get('entity').split('-')[-1]\n",
    "    if base_entity in base_entities:    \n",
    "        print(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0da87707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NlpHUST/ner-vietnamese-electra-base\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"NlpHUST/ner-vietnamese-electra-base\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = \"Sách Trang tử, theo Hán- thư Nghệ- Văn- Chí, thì có đến năm mươi hai(52) thiên. Nay chỉ thấy còn có ba mươi ba (33) thiên.\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8522b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nguyendangsonlam/lsg-ner-vietnamese-electra-base-1024\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"nguyendangsonlam/lsg-ner-vietnamese-electra-base-1024\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = \"Sách Trang tử, theo Hán- thư Nghệ- Văn- Chí, thì có đến năm mươi hai(52) thiên. Nay chỉ thấy còn có ba mươi ba (33) thiên.\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
