{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "model_path = \"nanonets/Nanonets-OCR-s\"\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_path, \n",
    "    torch_dtype=\"auto\", \n",
    "    device_map=\"auto\", \n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "processor = AutoProcessor.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "def ocr_page_with_nanonets_s(image_path, model, processor, max_new_tokens=4096):\n",
    "    prompt = \"\"\"Extract the text from the above document as if you were reading it naturally. Return the tables in html format. Return the equations in LaTeX representation. If there is an image in the document and image caption is not present, add a small description of the image inside the <img></img> tag; otherwise, add the image caption inside <img></img>. Watermarks should be wrapped in brackets. Ex: <watermark>OFFICIAL COPY</watermark>. Page numbers should be wrapped in brackets. Ex: <page_number>14</page_number> or <page_number>9/22</page_number>. Prefer using ☐ and ☑ for check boxes.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image\", \"image\": f\"file://{image_path}\"},\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "        ]},\n",
    "    ]\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = processor(text=[text], images=[image], padding=True, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(model.device)\n",
    "    \n",
    "    output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]\n",
    "    \n",
    "    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return output_text[0]\n",
    "\n",
    "image_path = \"/path/to/your/document.jpg\"\n",
    "result = ocr_page_with_nanonets_s(image_path, model, processor, max_new_tokens=15000)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try apt install\n",
      "\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n",
      "\u001b[31m   \u001b[0m sure you have python3-full installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytesseract'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymupdf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytesseract\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytesseract'"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import html\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    return unicodedata.normalize(\"NFC\", s.strip())\n",
    "\n",
    "def remove_html_entities(text):\n",
    "    \"\"\"Remove HTML entities comprehensively.\"\"\"\n",
    "    try:\n",
    "        text = html.unescape(text)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Remove &quot; and &quote; variations\n",
    "    text = text.replace(\"&quot;\", \"\")\n",
    "    text = text.replace(\"&quot\", \"\")\n",
    "    text = text.replace(\"&quote;\", \"\")\n",
    "    text = text.replace(\"&quote\", \"\")\n",
    "    text = text.replace(\"quot;\", \"\")\n",
    "    text = text.replace(\"quote;\", \"\")\n",
    "    \n",
    "    # Remove other common entities\n",
    "    html_entities = {\n",
    "        \"&amp;\": \"&\", \"&lt;\": \"<\", \"&gt;\": \">\", \"&apos;\": \"'\",\n",
    "        \"&nbsp;\": \" \", \"&hellip;\": \"...\", \"&mdash;\": \"—\", \"&ndash;\": \"–\"\n",
    "    }\n",
    "    \n",
    "    for entity, replacement in html_entities.items():\n",
    "        text = text.replace(entity, replacement)\n",
    "    \n",
    "    # Clean remaining entities with regex\n",
    "    text = re.sub(r\"&[a-zA-Z]+;?\", \"\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean text comprehensively.\"\"\"\n",
    "    text = normalize(text)\n",
    "    text = remove_html_entities(text)\n",
    "    \n",
    "    clean_patterns = [\"***\", \"---\", \"___\", \"...\"]\n",
    "    for pattern in clean_patterns:\n",
    "        text = text.replace(pattern, \"\")\n",
    "    \n",
    "    # Remove invisible characters and normalize spaces\n",
    "    text = re.sub(r\"[\\u200b\\u200e\\u202a\\u202c\\ufeff]+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def is_vietnamese(text: str) -> bool:\n",
    "    \"\"\"Check if text contains Vietnamese characters.\"\"\"\n",
    "    vietnamese_pattern = re.compile(r'[àáảãạăằắẳẵặâầấẩẫậèéẻẽẹêềếểễệìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵđĐ]')\n",
    "    return bool(vietnamese_pattern.search(text))\n",
    "\n",
    "def extract_images_from_pdf(pdf_path, output_dir=\"extracted_images\"):\n",
    "    \"\"\"Extract all images from PDF and save them.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    image_list = []\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        image_dict = page.get_images()\n",
    "        \n",
    "        for img_index, img in enumerate(image_dict):\n",
    "            xref = img[0]\n",
    "            pix = pymupdf.Pixmap(doc, xref)\n",
    "            \n",
    "            if pix.n - pix.alpha < 4:  # GRAY or RGB\n",
    "                img_filename = f\"333_BLOCK{page_num+1:03d}_LINE{img_index+1:03d}.png\"\n",
    "                img_path = os.path.join(output_dir, img_filename)\n",
    "                pix.save(img_path)\n",
    "                \n",
    "                image_list.append({\n",
    "                    'page': page_num + 1,\n",
    "                    'filename': img_filename,\n",
    "                    'path': img_path,\n",
    "                    'index': img_index + 1\n",
    "                })\n",
    "            \n",
    "            pix = None\n",
    "    \n",
    "    doc.close()\n",
    "    return image_list\n",
    "\n",
    "def ocr_image(image_path, lang='vie'):\n",
    "    \"\"\"Extract text from image using OCR.\"\"\"\n",
    "    try:\n",
    "        # Configure tesseract for Vietnamese\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        text = pytesseract.image_to_string(\n",
    "            Image.open(image_path), \n",
    "            lang=lang, \n",
    "            config=custom_config\n",
    "        )\n",
    "        return clean_text(text)\n",
    "    except Exception as e:\n",
    "        print(f\"OCR error for {image_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def split_sentences(text: str) -> list[str]:\n",
    "    \"\"\"Split text into Vietnamese sentences.\"\"\"\n",
    "    text = clean_text(text)\n",
    "    \n",
    "    # Split by common sentence delimiters\n",
    "    sentences = []\n",
    "    current_sentence = \"\"\n",
    "    \n",
    "    for char in text:\n",
    "        current_sentence += char\n",
    "        if char in [\".\", \"!\", \"?\", \"。\", \";\", \":\"]:\n",
    "            if current_sentence.strip():\n",
    "                cleaned = clean_text(current_sentence)\n",
    "                # Keep both Vietnamese and meaningful text\n",
    "                if cleaned and len(cleaned) > 5:\n",
    "                    sentences.append(cleaned)\n",
    "            current_sentence = \"\"\n",
    "    \n",
    "    # Add remaining text\n",
    "    if current_sentence.strip():\n",
    "        cleaned = clean_text(current_sentence)\n",
    "        if cleaned and len(cleaned) > 5:\n",
    "            sentences.append(cleaned)\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def process_images_with_ocr(pdf_path, output_file=\"ocr_results.txt\", start_line=13013):\n",
    "    \"\"\"Extract images from PDF and process with OCR, format like your example.\"\"\"\n",
    "    print(f\"🔄 Extracting images from PDF: {pdf_path}\")\n",
    "    \n",
    "    # Extract images\n",
    "    images = extract_images_from_pdf(pdf_path)\n",
    "    print(f\"📷 Found {len(images)} images\")\n",
    "    \n",
    "    # Process with OCR\n",
    "    results = []\n",
    "    line_number = start_line\n",
    "    \n",
    "    for img_info in images:\n",
    "        print(f\"🔍 Processing OCR for: {img_info['filename']}\")\n",
    "        ocr_text = ocr_image(img_info['path'])\n",
    "        \n",
    "        if ocr_text:\n",
    "            # Split into sentences or meaningful chunks\n",
    "            sentences = split_sentences(ocr_text)\n",
    "            \n",
    "            if not sentences:  # If no sentences found, use the whole text\n",
    "                sentences = [ocr_text]\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                if len(sentence.strip()) > 3:  # Only meaningful text\n",
    "                    result_line = f'\"{img_info[\"filename\"]}\": \"{sentence}\",'\n",
    "                    results.append((line_number, result_line))\n",
    "                    line_number += 1\n",
    "    \n",
    "    # Write results to file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for line_num, content in results:\n",
    "            f.write(f\"{line_num}\\t{content}\\n\")\n",
    "    \n",
    "    print(f\"✅ OCR results saved to: {output_file}\")\n",
    "    print(f\"📊 Total processed lines: {len(results)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_pdf_pages_ocr(pdf_path, output_file=\"page_ocr_results.txt\", start_line=13013):\n",
    "    \"\"\"Process entire PDF pages with OCR (alternative approach).\"\"\"\n",
    "    print(f\"🔄 Processing PDF pages with OCR: {pdf_path}\")\n",
    "    \n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    results = []\n",
    "    line_number = start_line\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        # Convert page to image\n",
    "        mat = pymupdf.Matrix(2.0, 2.0)  # Increase resolution\n",
    "        pix = page.get_pixmap(matrix=mat)\n",
    "        img_path = f\"temp_page_{page_num+1}.png\"\n",
    "        pix.save(img_path)\n",
    "        \n",
    "        print(f\"🔍 Processing OCR for page {page_num+1}\")\n",
    "        ocr_text = ocr_image(img_path)\n",
    "        \n",
    "        if ocr_text:\n",
    "            sentences = split_sentences(ocr_text)\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                if len(sentence.strip()) > 5:\n",
    "                    filename = f\"333_BLOCK{page_num+1:03d}_LINE{len(results)+1:03d}.png\"\n",
    "                    result_line = f'\"{filename}\": \"{sentence}\",'\n",
    "                    results.append((line_number, result_line))\n",
    "                    line_number += 1\n",
    "        \n",
    "        # Clean up temp file\n",
    "        if os.path.exists(img_path):\n",
    "            os.remove(img_path)\n",
    "        \n",
    "        pix = None\n",
    "    \n",
    "    doc.close()\n",
    "    \n",
    "    # Write results to file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for line_num, content in results:\n",
    "            f.write(f\"{line_num}\\t{content}\\n\")\n",
    "    \n",
    "    print(f\"✅ OCR results saved to: {output_file}\")\n",
    "    print(f\"📊 Total processed lines: {len(results)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Method 1: Extract embedded images and OCR them\n",
    "    # results = process_images_with_ocr(\"your_pdf_file.pdf\", \"image_ocr_output.txt\")\n",
    "    \n",
    "    # Method 2: Convert each page to image and OCR (recommended for scanned PDFs)\n",
    "    results = process_pdf_pages_ocr(\"/home/octoopt/workspace/projects/learn-from-basics/nlp-vietnamese-phd/temp/TRANG TỬ NAM HOA KINH.pdf\", \"page_ocr_output.txt\")\n",
    "    \n",
    "    \n",
    "    print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
